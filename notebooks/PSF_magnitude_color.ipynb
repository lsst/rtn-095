{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d05a35-93ec-4afe-8b3b-de7bed0dfe7f",
   "metadata": {},
   "source": [
    "# Analysis / plot to compare PSF residuals and photometry / color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97219e01-3502-4656-a9e7-4a22e1a67d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsst.daf.butler import Butler\n",
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "from smatch.matcher import Matcher\n",
    "from tqdm import tqdm\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from lsst.utils.plotting import publication_plots\n",
    "publication_plots.set_rubin_plotstyle()\n",
    "import pickle\n",
    "\n",
    "import lsst.afw.cameraGeom as cameraGeom\n",
    "from lsst.obs.lsst import LsstComCam\n",
    "\n",
    "\n",
    "from scipy.stats import binned_statistic\n",
    "import fitsio\n",
    "import os\n",
    "from astropy.stats import median_absolute_deviation as mad_astropy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0363bc-99b8-4de6-bf0d-5e8422f86a07",
   "metadata": {},
   "source": [
    "Some code to do 1d histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bd4a4-877e-481a-83d4-df93c219f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biweight_median(sample, CSTD=6.):\n",
    "    \"\"\"\n",
    "    Median with outlier rejection using mad clipping.\n",
    "    Using the biweight described in Beers 1990 (Used originaly\n",
    "    for finding galaxy clusters redshfit).\n",
    "\n",
    "    :param sample: 1d numpy array. The sample where you want\n",
    "                   to compute the median with outlier rejection.\n",
    "    :param CSTD:   float. Constant used in the algorithm of the\n",
    "                   Beers 1990. [default: 6.]\n",
    "    \"\"\"\n",
    "    M = np.median(sample)\n",
    "    iterate = [copy.deepcopy(M)]\n",
    "    mu = (sample-M) / (CSTD*mad_astropy(sample))\n",
    "    Filtre = (abs(mu)<1)\n",
    "    up = (sample-M) * ((1.-mu**2)**2)\n",
    "    down = (1.-mu**2)**2\n",
    "    M += np.sum(up[Filtre])/np.sum(down[Filtre])\n",
    "\n",
    "    iterate.append(copy.deepcopy(M))\n",
    "    i = 1\n",
    "    while abs((iterate[i-1]-iterate[i])/iterate[i])<0.001:\n",
    "        mu = (sample-M) / (CSTD*mad_astropy(sample))\n",
    "        Filtre = (abs(mu)<1)\n",
    "        up = (sample-M) * ((1.-mu**2)**2)\n",
    "        down = (1.-mu**2)**2\n",
    "        M += np.sum(up[Filtre])/np.sum(down[Filtre])\n",
    "        iterate.append(copy.deepcopy(M))\n",
    "        i += 1\n",
    "        if i == 100 :\n",
    "            print('Fail to converge')\n",
    "            break\n",
    "    return M\n",
    "\n",
    "def biweight_mad(sample, CSTD=9.):\n",
    "    \"\"\"\n",
    "    Median absolute deviation with outlier rejection using mad clipping.\n",
    "    Using the biweight described in Beers 1990 (Used originaly\n",
    "    for finding galaxy clusters peculiar velocity dispersion).\n",
    "\n",
    "    :param sample: 1d numpy array. The sample where you want\n",
    "                   to compute the mad with outlier rejection.\n",
    "    :param CSTD:   float. Constant used in the algorithm of the\n",
    "                   Beers 1990. [default: 9.]\n",
    "    \"\"\"\n",
    "    M = biweight_median(sample)\n",
    "    mu = (sample-M) / (CSTD*mad_astropy(sample))\n",
    "    Filtre = (abs(mu)<1)\n",
    "    up = ((sample-M)**2)*((1.-mu**2)**4)\n",
    "    down = (1.-mu**2)*(1.-5.*mu**2)\n",
    "    mad = np.sqrt(len(sample)) * (np.sqrt(np.sum(up[Filtre]))/abs(np.sum(down[Filtre])))\n",
    "    return mad\n",
    "\n",
    "\n",
    "class meanify1D_wrms():\n",
    "    \"\"\"Take data, build a 1d average, and write output average.\n",
    "\n",
    "    :param bin_spacing: Bin_size, resolution on the mean function. (default=0.3)\n",
    "    \"\"\"\n",
    "    def __init__(self, bin_spacing=0.3):\n",
    "\n",
    "        self.bin_spacing = bin_spacing\n",
    "\n",
    "        self.coords = []\n",
    "        self.params = []\n",
    "        self.params_err = []\n",
    "\n",
    "    def add_data(self, coord, param, params_err=None):\n",
    "        \"\"\"\n",
    "        Add new data to compute the mean function. \n",
    "\n",
    "        :param coord: Array of coordinate of the parameter.\n",
    "        :param param: Array of parameter.\n",
    "        \"\"\"\n",
    "        self.coords.append(coord)\n",
    "        self.params.append(param)\n",
    "        if params_err is None:\n",
    "            self.params_err = None\n",
    "        else:\n",
    "            self.params_err.append(params_err)\n",
    "\n",
    "    def sigma_clipping(self, sigma=3.):\n",
    "        self.std = []\n",
    "        nvisits = len(self.params)\n",
    "        for i in range(nvisits):\n",
    "            self.std.append(np.std(self.params[i]))\n",
    "        #mean, std = np.mean(self.std), np.std(self.std)\n",
    "        mean, std = biweight_median(self.std), biweight_mad(self.std)\n",
    "\n",
    "        I = 0\n",
    "        for i in range(nvisits):\n",
    "            if self.std[i] > mean + sigma * std:\n",
    "                print('PF:', i)\n",
    "                del self.params[I]\n",
    "                if self.params_err is not None:\n",
    "                    del self.params_err[I]\n",
    "                del self.coords[I]\n",
    "            else:\n",
    "                I+=1\n",
    "        print('Number of visit removed / nvisits: ',\n",
    "              nvisits - len(self.params), '/', nvisits)\n",
    "\n",
    "    def meanify(self, x_min=None, x_max=None):\n",
    "        \"\"\"\n",
    "        Compute the mean function.\n",
    "        \"\"\"\n",
    "        # self.sigma_clipping(sigma=3.)\n",
    "        params = np.concatenate(self.params)\n",
    "        coords = np.concatenate(self.coords)\n",
    "        if self.params_err is not None:\n",
    "            params_err = np.concatenate(self.params_err)\n",
    "        else:\n",
    "            params_err = np.ones_like(params)\n",
    "\n",
    "        weights = 1./params_err**2\n",
    "\n",
    "        if x_min is None:\n",
    "            x_min = np.min(coords)\n",
    "        if x_max is None:\n",
    "            x_max = np.max(coords)\n",
    "\n",
    "        nbin = int((x_max - x_min) / self.bin_spacing)\n",
    "\n",
    "        binning = np.linspace(x_min, x_max, nbin)\n",
    "        Filter = np.array([True]*nbin)\n",
    "\n",
    "\n",
    "        sum_wpp, x0, bin_target = binned_statistic(coords, weights*params*params,\n",
    "                                                   bins=binning, statistic='sum')\n",
    "\n",
    "        sum_wp, x0, bin_target = binned_statistic(coords, weights*params,\n",
    "                                                  bins=binning, statistic='sum')\n",
    "\n",
    "        sum_w, x0, bin_target = binned_statistic(coords, weights,\n",
    "                                                 bins=binning, statistic='sum')\n",
    "\n",
    "        average = sum_wp / sum_w\n",
    "        wvar = (1. / sum_w) * (sum_wpp - 2.*average*sum_wp + average*average*sum_w)\n",
    "        wrms = np.sqrt(wvar)\n",
    "\n",
    "        # get center of each bin \n",
    "        x0 = x0[:-1] + (x0[1] - x0[0])/2.\n",
    "\n",
    "        # remove any entries with nan (counts == 0 and non finite value in\n",
    "        # the 1D statistic computation) \n",
    "        self.x0 = x0\n",
    "        self.average = average\n",
    "        self.wrms= wrms\n",
    "\n",
    "    def save_results(self, name_output='wrms_mag.fits'):\n",
    "        \"\"\"\n",
    "        Write output mean function.\n",
    "        \n",
    "        :param name_output: Name of the output fits file. (default: 'mean_gp.fits')\n",
    "        \"\"\"\n",
    "        dtypes = [('X0', self.x0.dtype, self.x0.shape),\n",
    "                  ('AVERAGE', self.average.dtype, self.average.shape),\n",
    "                  ('WRMS', self.wrms.dtype, self.wrms.shape),\n",
    "                  ]\n",
    "        data = np.empty(1, dtype=dtypes)\n",
    "        \n",
    "        data['X0'] = self.x0\n",
    "        data['AVERAGE'] = self.average\n",
    "        data['WRMS'] = self.wrms\n",
    "\n",
    "        with fitsio.FITS(name_output,'rw',clobber=True) as f:\n",
    "            f.write_table(data, extname='average_solution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce5f8cf-b5f5-44f1-b42b-121b55781dd6",
   "metadata": {},
   "source": [
    "The data from DP1 used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8898115-daec-4916-9ea2-eddacbccdfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"/repo/main\"\n",
    "collection = \"LSSTComCam/runs/DRP/DP1/v29_0_0_rc6/DM-50098\"\n",
    "\n",
    "butler = Butler(repo, collections=collection)\n",
    "sourceTable_visit_dsrs = list(butler.registry.queryDatasets(\"refit_psf_star\"))\n",
    "visit_ids = []\n",
    "\n",
    "for dsr in sourceTable_visit_dsrs:\n",
    "    visit_ids.append(dsr.dataId[\"visit\"])\n",
    "\n",
    "print(len(visit_ids))\n",
    "print(len(set(visit_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268f55f-22cc-40c7-a8bb-31af91ecbc2d",
   "metadata": {},
   "source": [
    "Do the match at visit level between FGCM photometry and PSF stats from Piff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6071544-1184-489b-a188-8d03d2d2083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITE = False\n",
    "\n",
    "if WRITE: \n",
    "\n",
    "    \n",
    "    dic = {}\n",
    "    butler = Butler(repo, collections=collection)\n",
    "\n",
    "    for visit in tqdm(visit_ids):\n",
    "\n",
    "        try: \n",
    "        \n",
    "            finalized_src_table = butler.get(\"refit_psf_star\", visit=visit)\n",
    "            visitSummary = butler.get(\"preliminary_visit_summary\", visit=visit)\n",
    "\n",
    "            # Highly inspired but what is done in GBDES for DCR correction.\n",
    "\n",
    "            colorCatalog = butler.get(\"fgcm_Cycle5_StandardStars\")\n",
    "            catalogBands = colorCatalog.metadata.getArray(\"BANDS\")\n",
    "            colorInd1 = catalogBands.index(\"r\")\n",
    "            colorInd2 = catalogBands.index(\"z\")\n",
    "            colors = colorCatalog[\"mag_std_noabs\"][:, colorInd1] - colorCatalog[\"mag_std_noabs\"][:, colorInd2]\n",
    "            mag = colorCatalog[\"mag_std_noabs\"][:, colorInd1]\n",
    "            goodInd = (colorCatalog[\"mag_std_noabs\"][:, colorInd1] != 99.0) & (\n",
    "                colorCatalog[\"mag_std_noabs\"][:, colorInd2] != 99.0\n",
    "            )\n",
    "            ra_psf = (finalized_src_table['coord_ra'] * u.radian).to(u.degree).value\n",
    "            dec_psf = (finalized_src_table['coord_dec'] * u.radian).to(u.degree).value\n",
    "\n",
    "            with Matcher(ra_psf, dec_psf) as matcher:\n",
    "                idx, idx_starCat, idx_colorCat, d = matcher.query_radius(\n",
    "                    (colorCatalog[goodInd][\"coord_ra\"] * u.radian).to(u.degree).value,\n",
    "                    (colorCatalog[goodInd][\"coord_dec\"] * u.radian).to(u.degree).value,\n",
    "                    1. / 3600.0,\n",
    "                    return_indices=True,\n",
    "                )\n",
    "            \n",
    "            table = finalized_src_table\n",
    "            table['ixx_src'] = table['slot_Shape_xx']\n",
    "            table['ixy_src'] = table['slot_Shape_xy']\n",
    "            table['iyy_src'] = table['slot_Shape_yy']\n",
    "            \n",
    "            table['ixx_psf'] = table['slot_PsfShape_xx']\n",
    "            table['ixy_psf'] = table['slot_PsfShape_xy']\n",
    "            table['iyy_psf'] = table['slot_PsfShape_yy']\n",
    "            \n",
    "            table['T_src'] = table['ixx_src'] + table['iyy_src']\n",
    "            table['e1_src'] = (table['ixx_src'] - table['iyy_src']) / table['T_src']\n",
    "            table['e2_src'] = 2*table['ixy_src'] / table['T_src']\n",
    "            \n",
    "            table['T_psf'] = table['ixx_psf'] + table['iyy_psf']\n",
    "            table['e1_psf'] = (table['ixx_psf'] - table['iyy_psf']) / table['T_psf']\n",
    "            table['e2_psf'] = 2*table['ixy_psf'] / table['T_psf']\n",
    "\n",
    "            dT_T = np.array((table['T_src'] - table['T_psf']) / table['T_src'])\n",
    "            de1 = np.array(table['e1_src'] - table['e1_psf'])\n",
    "            de2 = np.array(table['e2_src'] - table['e2_psf'])\n",
    "\n",
    "        \n",
    "            dic.update({\n",
    "                visit: {\n",
    "                   'dT_T': dT_T[idx_starCat],\n",
    "                    'de1': de1[idx_starCat],\n",
    "                    'de2': de2[idx_starCat],\n",
    "                    'color': colors[goodInd][idx_colorCat],\n",
    "                    'mag': mag[goodInd][idx_colorCat],\n",
    "                    'band': visitSummary[0][\"band\"],\n",
    "                    \n",
    "                }\n",
    "            })\n",
    "\n",
    "        except:\n",
    "            dic.update({\n",
    "                visit: None,\n",
    "            })\n",
    "    \n",
    "    f = open('master_dic_color.pkl', 'wb')\n",
    "    pickle.dump(dic, f)\n",
    "    f.close()\n",
    "    master_dic = pickle.load(open('master_dic_color.pkl', 'rb'))\n",
    "else:\n",
    "\n",
    "    master_dic = pickle.load(open('master_dic_color.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153468b-59ae-4bdd-b4e8-a7d03ecac1c0",
   "metadata": {},
   "source": [
    "Do the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c215a-b53a-4332-a2ec-c7c04eb7d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0\n",
    "bin_spacing = 0.5\n",
    "XMIN = 15.5\n",
    "XMAX = 22.5\n",
    "\n",
    "key = 'dT_T'\n",
    "\n",
    "meanifyAll = meanify1D_wrms(bin_spacing=bin_spacing)\n",
    "\n",
    "meanifyLowColor = meanify1D_wrms(bin_spacing=bin_spacing)\n",
    "meanifyMidColor = meanify1D_wrms(bin_spacing=bin_spacing)\n",
    "meanifyHighColor = meanify1D_wrms(bin_spacing=bin_spacing)\n",
    "\n",
    "for visit in master_dic:\n",
    "    if master_dic[visit] is not None:\n",
    "\n",
    "        isFinite = np.isfinite(master_dic[visit][key])\n",
    "        meanifyAll.add_data(master_dic[visit]['mag'][isFinite],  master_dic[visit][key][isFinite], params_err=None)\n",
    "\n",
    "        lowColor = isFinite & (master_dic[visit]['color'] < 1)\n",
    "        meanifyLowColor.add_data(master_dic[visit]['mag'][lowColor],  master_dic[visit][key][lowColor], params_err=None)\n",
    "        \n",
    "        \n",
    "        midColor = isFinite & (master_dic[visit]['color'] > 1) & (master_dic[visit]['color'] < 2)\n",
    "        meanifyMidColor.add_data(master_dic[visit]['mag'][midColor],  master_dic[visit][key][midColor], params_err=None)\n",
    "\n",
    "        \n",
    "        highColor = isFinite & (master_dic[visit]['color'] > 2)\n",
    "        meanifyHighColor.add_data(master_dic[visit]['mag'][highColor],  master_dic[visit][key][highColor], params_err=None)\n",
    "        \n",
    "    else:\n",
    "        N += 1\n",
    "\n",
    "\n",
    "\n",
    "meanifyAll.meanify(x_min=XMIN, x_max=XMAX)\n",
    "meanifyLowColor.meanify(x_min=XMIN, x_max=XMAX)\n",
    "meanifyMidColor.meanify(x_min=XMIN, x_max=XMAX)\n",
    "meanifyHighColor.meanify(x_min=XMIN, x_max=XMAX)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(meanifyAll.x0, meanifyAll.average, c='k', label=\"all\")\n",
    "plt.scatter(meanifyLowColor.x0, meanifyLowColor.average, c='b', label=r\"$r-z$ = 0. - 1.\")\n",
    "plt.scatter(meanifyMidColor.x0, meanifyMidColor.average, c='y', label=r\"$r-z$ = 1. - 2.\")\n",
    "plt.scatter(meanifyHighColor.x0, meanifyHighColor.average, c='r', label=r\"$r-z$ = 2. - 4.\")\n",
    "\n",
    "\n",
    "plt.plot([15, 23], [0, 0.], 'k--')\n",
    "plt.ylim(-0.015, 0.015)\n",
    "plt.xlim(15.9, 22.5)\n",
    "\n",
    "plt.xlabel('Magnitude')\n",
    "plt.ylabel('$\\\\left<\\\\left(T_{\\\\text{PSF}} - T_{\\\\text{model}}\\\\right) \\\\ / \\\\ T_{\\\\text{PSF}}\\\\right>$')\n",
    "plt.legend()\n",
    "plt.savefig('../figures/dT_T_Piff_poly_4_vs_mag.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e408a4-0f8f-4e07-928e-d81806697e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
